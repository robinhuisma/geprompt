---
title: "Guide Labs lanceert doorzichtige taalmodel Steerling-8B als open source"
date: 2026-02-23T18:00:22.026Z
tags: ["ai", "machine learning", "open source", "llm"]
summary: "Het AI-bedrijf Guide Labs heeft een nieuw soort interpreteerbaar groot taalmodel gelanceerd, genaamd Steerling-8B, dat als open source beschikbaar is."
cover:
  image: "https://images.pexels.com/photos/8533136/pexels-photo-8533136.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940"
  alt: "Scientist in a lab coat handling test tubes under pink lighting, using a microscope."
  caption: "Foto: Artem Podrez via Pexels"
draft: false
---

Guide Labs heeft een nieuw groot taalmodel (LLM) geïntroduceerd dat is ontworpen om de interne werking en besluitvorming transparanter en beter te begrijpen voor ontwikkelaars. Het model, Steerling-8B, telt 8 miljard parameters en is vrijgegeven als open source. De kern van de innovatie ligt in een nieuwe modelarchitectuur die specifiek is gebouwd om interpretatie en controle te vergemakkelijken.

Bij conventionele LLM's is het vaak een "black box"; het is moeilijk te achterhalen waarom het model een bepaalde output genereert. De architectuur van Steerling-8B, ontwikkeld door het team van Guide Labs, poogt dit fundamentele probleem aan te pakken. Het model is zo gestructureerd dat zijn interne processen en de redenen voor zijn acties beter traceerbaar en verklaarbaar moeten zijn voor onderzoekers en ingenieurs. Deze doorzichtigheid kan leiden tot betere debugging, nauwkeurigere afstemming op specifieke taken en meer vertrouwen bij de inzet van de technologie.

De beslissing om het model open source te maken, betekent dat de volledige code en gewichten vrij beschikbaar zijn voor de gemeenschap. Dit stelt ontwikkelaars en onderzoekers wereldwijd in staat om het model te testen, te verbeteren en te integreren in hun eigen projecten zonder licentiebeperkingen. Het bevordert samenwerking en versnelt mogelijk de innovatie op het gebied van interpreteerbare AI.

Voor een ondernemer of professional in de technologie betekent deze ontwikkeling een stap voorwaarts in het praktisch en verantwoord inzetten van geavanceerde AI. Een beter interpreteerbaar model kan het risicomanagement verbeteren, bijvoorbeeld bij geautomatiseerde klantenservice of contentgeneratie, waar het cruciaal is om de bron van een fout of een bias te kunnen begrijpen. Het opent ook de deur voor meer gespecialiseerde en betrouwbare toepassingen in gevoelige domeinen zoals juridische analyse, medisch onderzoek of financiële advisering, waar uitlegbaarheid niet alleen een technische wens maar vaak een wettelijke vereiste is.

Bron: Guide Labs