---
title: "Anthropic splitst Claude-crawler op voor meer controle over je website"
date: 2026-02-27T22:59:43.467Z
tags: ["anthropic", "claude", "robots.txt", "webcrawler"]
categorieen: ["nieuws-tools"]
summary: "Website-eigenaren krijgen meer controle over hoe AI-bedrijf Anthropic hun content gebruikt, dankzij een splitsing van de crawler."
cover:
  image: "https://images.pexels.com/photos/10480828/pexels-photo-10480828.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940"
  alt: "Man stands behind a car and stop tape at night, creating a mysterious scene."
  caption: "Foto: cottonbro studio via Pexels"
draft: false
---

Anthropic heeft zijn webcrawler opgesplitst in drie aparte bots, waardoor je als website-eigenaar preciezer kunt bepalen welke data het AI-bedrijf mag gebruiken. Het gaat om aparte bots voor het trainen van AI-modellen, voor het indexeren van content voor zoekfuncties en voor het verwerken van directe gebruikersvragen.

Deze wijziging geeft je meer controle via het robots.txt-bestand op je server. Je kunt nu bijvoorbeeld toestaan dat Claude content indexeert voor zijn interne zoekfunctie, maar weigeren dat dezelfde content wordt gebruikt om toekomstige AI-modellen te trainen. Volgens Search Engine Journal brengt elke blokkade wel een afweging met zich mee; als je de training-bot blokkeert, kan dat de prestaties van Claude op jouw content be√Ønvloeden.

Voor ondernemers betekent dit dat je een bewustere keuze kunt maken over AI-training. Wil je bijdragen aan de ontwikkeling van tools als Claude, of liever niet? Je kunt dit nu per bot instellen. Het is een goed moment om je robots.txt-beleid tegen het licht te houden en te beslissen hoe je wilt dat grote AI-spelers met jouw publieke content omgaan.

*Dit artikel is geschreven met behulp van AI en gecontroleerd door de redactie van geprompt.nl.*

Bron: [Search Engine Journal](https://www.searchenginejournal.com/anthropics-claude-bots-make-robots-txt-decisions-more-granular/568253/)
