---
title: "Anthropic splitst Claude-crawler op voor meer controle over je website"
date: 2026-02-27T23:15:54.892Z
tags: ["anthropic", "claude", "robots.txt", "webcrawlers"]
categorieen: ["nieuws-tools"]
summary: "Je kunt nu specifieker bepalen welke versie van Claude je website mag crawlen voor training, zoeken of gebruikersvragen."
cover:
  image: "https://images.pexels.com/photos/30530404/pexels-photo-30530404.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940"
  alt: "A detailed view of the DeepSeek AI interface, displaying a welcoming message on a dark background."
  caption: "Foto: Matheus Bertelli via Pexels"
draft: false
---

Anthropic heeft zijn webcrawlers opgesplitst in drie aparte 'bots'. Dit betekent dat je als website-eigenaar nu gedetailleerder kunt bepalen welke versie van de AI je site mag bezoeken.

Voorheen was er één crawler voor alle doeleinden. Nu zijn er aparte bots voor het trainen van het AI-model, het indexeren voor zoekresultaten in Claude, en het verwerken van live gebruikersvragen. In de robots.txt van je site kun je elke bot individueel toestaan of blokkeren. Volgens het bedrijf zijn er wel afwegingen: als je de training-bot blokkeert, kan Claude mogelijk minder goed antwoorden geven op vragen over de inhoud van je site.

Voor ondernemers die hun content strategisch inzetten, biedt dit meer regie. Wil je dat Claude je kennisartikelen kan lezen om vragen van gebruikers te beantwoorden, maar niet dat de tekst wordt gebruikt om het basis AI-model te trainen? Dat onderscheid kun je nu maken. Het is een praktische stap voor wie bewust omgaat met hoe AI zijn content gebruikt.

De update is terug te vinden in de officiële crawler-documentatie van Anthropic.

*Dit artikel is geschreven met behulp van AI en gecontroleerd door de redactie van geprompt.nl.*

Bron: [Search Engine Journal](https://www.searchenginejournal.com/anthropics-claude-bots-make-robots-txt-decisions-more-granular/568253/)
